{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4093953b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24dfae8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the image path: ;;\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-b2788b0a8cf2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Enter the image path: \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mimg_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-b2788b0a8cf2>\u001b[0m in \u001b[0;36mget_path\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m   \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Enter the image path: \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m    858\u001b[0m                 \u001b[1;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m             )\n\u001b[1;32m--> 860\u001b[1;33m         return self._input_request(str(prompt),\n\u001b[0m\u001b[0;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m    902\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    903\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 904\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Interrupted by user\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    905\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid Message:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "def show_image(img):\n",
    "  plt.figure()\n",
    "  plt.imshow(img, cmap=plt.cm.binary)\n",
    "  plt.colorbar()\n",
    "  plt.grid(False)\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "def get_path():\n",
    "  while True:\n",
    "    path = input(\"Enter the image path: \")\n",
    "    return path\n",
    "img_path = get_path();\n",
    "img = image.load_img(img_path, target_size=(32,32,3))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "image=np.array(x);\n",
    "image[0,1,3]\n",
    "show_image(image[0]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "105464d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  LOAD AND SPLIT DATASET\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "test_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "997aa279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's look at a one image\n",
    "IMG_INDEX = 7  # change this to look at other images\n",
    "\n",
    "plt.imshow(train_images[IMG_INDEX] ,cmap=plt.cm.binary)\n",
    "plt.xlabel(class_names[train_labels[IMG_INDEX][0]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7467cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aab72112",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ae4fcc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 64)          36928     \n",
      "=================================================================\n",
      "Total params: 56,320\n",
      "Trainable params: 56,320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()  # let's have a look at our model so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95055b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e708de04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                65600     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 122,570\n",
      "Trainable params: 122,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "811bd93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 37s 24ms/step - loss: 1.5218 - accuracy: 0.4457 - val_loss: 1.2216 - val_accuracy: 0.5614\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 42s 27ms/step - loss: 1.1504 - accuracy: 0.5920 - val_loss: 1.1099 - val_accuracy: 0.6048\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 44s 28ms/step - loss: 0.9925 - accuracy: 0.6506 - val_loss: 0.9600 - val_accuracy: 0.6605\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 39s 25ms/step - loss: 0.8973 - accuracy: 0.6857 - val_loss: 0.9178 - val_accuracy: 0.6793\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 39s 25ms/step - loss: 0.8268 - accuracy: 0.7095 - val_loss: 0.9355 - val_accuracy: 0.6726\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 37s 23ms/step - loss: 0.7708 - accuracy: 0.7292 - val_loss: 0.9021 - val_accuracy: 0.6866\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 34s 22ms/step - loss: 0.7218 - accuracy: 0.7464 - val_loss: 0.8646 - val_accuracy: 0.7027\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 37s 24ms/step - loss: 0.6807 - accuracy: 0.7612 - val_loss: 0.8395 - val_accuracy: 0.7103\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 36s 23ms/step - loss: 0.6499 - accuracy: 0.7708 - val_loss: 0.8359 - val_accuracy: 0.7175\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 35s 22ms/step - loss: 0.6160 - accuracy: 0.7827 - val_loss: 0.8779 - val_accuracy: 0.7107\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_images, train_labels, epochs=10, \n",
    "                    validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a3475d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 2s - loss: 0.8779 - accuracy: 0.7107\n",
      "0.7106999754905701\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65c65b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 32, 32, 3)\n",
      "(32, 32, 3)\n",
      "(32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# creates a data generator object that transforms images\n",
    "datagen = ImageDataGenerator(\n",
    "rotation_range=40,\n",
    "width_shift_range=0.2,\n",
    "height_shift_range=0.2,\n",
    "shear_range=0.2,\n",
    "zoom_range=0.2,\n",
    "horizontal_flip=True,\n",
    "fill_mode='nearest')\n",
    "\n",
    "# pick an image to transform\n",
    "test_img = train_images[20]\n",
    "img = image.img_to_array(test_img)  # convert image to numpy arry\n",
    "img = img.reshape((1,) + img.shape)  # reshape image\n",
    "print(img.shape)\n",
    "\n",
    "i = 0\n",
    "\n",
    "for batch in datagen.flow(img, save_prefix='test', save_format='jpeg'):  # this loops runs forever until we break, saving images to current directory with specified prefix\n",
    "#     plt.figure(i)\n",
    "    new_image=image.img_to_array(batch[0])\n",
    "    print(new_image.shape)\n",
    "#     plot = plt.imshow()\n",
    "    i += 1\n",
    "    if i > 1:  # show 4 images\n",
    "        break\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2d8cd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"dogs_vs_cats.h5\")  # we can save the model and reload it at anytime in the future\n",
    "new_model = tf.keras.models.load_model('dogs_vs_cats.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5801292",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (160, 160, 3)\n",
    "\n",
    "# Create the base model from the pre-trained model MobileNet V2\n",
    "model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1925cc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, image):\n",
    "  class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "  show_image(image)\n",
    "\n",
    "def show_image(img):\n",
    "  plt.figure()\n",
    "  plt.imshow(img, cmap=plt.cm.binary)\n",
    "  plt.colorbar()\n",
    "  plt.grid(False)\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "def get_path():\n",
    "  while True:\n",
    "    path = input(\"Enter the image path: \")\n",
    "    return path\n",
    "img_path = get_path()\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "predict(model, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580a5cec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
